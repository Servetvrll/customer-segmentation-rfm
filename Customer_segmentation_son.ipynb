{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1lAmXdzB6cbmdOnTzG2GlaaS6HlVBvD1y",
      "authorship_tag": "ABX9TyPGBPBtSv5tQVkGMc0LdsnE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Servetvrll/customer-segmentation-rfm/blob/main/Customer_segmentation_son.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BFBpcm8NEe22"
      },
      "outputs": [],
      "source": [
        "# Gerekli kütüphaneleri projem için içeri aktarıyorum.\n",
        "# numpy: Sayısal işlemler için.\n",
        "# pandas: Veri manipülasyonu ve analizi için.\n",
        "# matplotlib.pyplot: Statik, interaktif ve animasyonlu görselleştirmeler için.\n",
        "# seaborn: Matplotlib üzerine kurulu, daha çekici istatistiksel grafikler oluşturmak için.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Veri setimi Google Drive'ımdan yüklüyorum.\n",
        "# Colab ortamında çalıştığım için dosya yolunu bu şekilde belirtiyorum.\n",
        "# Veri setine erişmek için kaggle linki \"https://www.kaggle.com/datasets/arjunbhasin2013/ccdata\"\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Customer_Segmentation/custemer_segmentation.csv\")\n",
        "\n",
        "# Veri setime ilk bakışı atıyorum:\n",
        "# İlk 5 satırı görüntüleyerek verinin genel yapısı hakkında fikir ediniyorum.\n",
        "print(\"Veri setimin ilk 5 satırı:\")\n",
        "print(data.head())\n",
        "print(\"-----------------------------------------\")\n",
        "\n",
        "# Son 5 satırı görüntüleyerek verinin sonuna doğru bir kontrol yapıyorum.\n",
        "print(\"Veri setimin son 5 satırı:\")\n",
        "print(data.tail())\n",
        "print(\"-----------------------------------------\")\n",
        "\n",
        "# Veri tiplerini ve her sütundaki boş (null) olmayan değer sayısını inceliyorum.\n",
        "# Bu, eksik veri olup olmadığını ve sütunların doğru veri tipinde olup olmadığını anlamamı sağlıyor.\n",
        "print(\"Veri tipleri ve boş (non-null) değer sayıları:\")\n",
        "print(data.info())\n",
        "print(\"-----------------------------------------\")\n",
        "\n",
        "# Sayısal sütunların temel istatistiksel özetlerini (ortalama, standart sapma, min, max vb.) görüntülüyorum.\n",
        "# Bu, verinin dağılımı ve olası aykırı değerler hakkında ilk ipuçlarını veriyor.\n",
        "print(\"Sayısal sütunlarımın istatistiksel özeti:\")\n",
        "\n",
        "print(data.describe())\n",
        "print(\"-----------------------------------------\")\n",
        "\n",
        "# Her sütundaki toplam boş (NaN) değer sayısını kontrol ediyorum.\n",
        "# Bu, veri temizleme adımlarım için hangi sütunlara odaklanmam gerektiğini gösteriyor.\n",
        "print(\"Her sütundaki toplam boş (NaN) değer sayısı:\")\n",
        "print(data.isnull().sum())\n",
        "print(\"-----------------------------------------\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 'CUST_ID' sütununu veri setimden çıkarıyorum.\n",
        "# Bu sütun, müşteri kimlik bilgisini içerdiği için kümeleme analizi için bir özellik olarak kullanılmaz ve gereksizdir.\n",
        "data.drop([\"CUST_ID\"], axis=1, inplace=True)\n",
        "print(\"CUST_ID sütunu silindikten sonra veri setimin ilk 5 satırı:\")\n",
        "print(data.head())\n",
        "\n",
        "# Eksik değerleri doldurma (imputation) ve silme işlemleri:\n",
        "# 'MINIMUM_PAYMENTS' sütunundaki boş değerleri 0 ile dolduruyorum.\n",
        "# Müşterinin minimum ödeme yapması gerekmediği veya hiç ödeme oluşmadığı durumları temsil edebileceğini varsaydım.\n",
        "data[\"MINIMUM_PAYMENTS\"] = data[\"MINIMUM_PAYMENTS\"].fillna(0)\n",
        "\n",
        "# 'CREDIT_LIMIT' sütununda sadece tek bir boş değer olduğunu tespit ettim.\n",
        "# Bu tek satırı silmek, veri kaybını minimumda tutarken veri setimi temizlememi sağlıyor.\n",
        "data.dropna(subset=['CREDIT_LIMIT'], inplace=True)\n",
        "print(\"\\nBoş değerler temizlendikten sonraki durum (tekrar kontrol):\")\n",
        "print(data.isnull().sum())\n"
      ],
      "metadata": {
        "id": "NSISyb6SEjFL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kümeleme için kullanacağım sütunları belirliyorum.\n",
        "# Bu sütunlar, müşteri davranışlarını ve finansal özelliklerini yansıtan önemli değişkenlerdir.\n",
        "columns =['BALANCE',  'PURCHASES', 'ONEOFF_PURCHASES',\n",
        "       'INSTALLMENTS_PURCHASES', 'CASH_ADVANCE','ONEOFF_PURCHASES_FREQUENCY', 'PURCHASES_INSTALLMENTS_FREQUENCY',\n",
        "       'CASH_ADVANCE_FREQUENCY', 'CASH_ADVANCE_TRX', 'PURCHASES_TRX',\n",
        "       'CREDIT_LIMIT', 'PAYMENTS', 'MINIMUM_PAYMENTS'\n",
        "       ]\n",
        "df_new = data[columns]\n",
        "\n",
        "# Veri setimdeki sayısal değişkenlerin dağılımını histogramlarla görselleştiriyorum.\n",
        "# Bu grafikler, her bir değişkenin nasıl dağıldığını, çarpık olup olmadığını ve olası aykırı değerleri görmemi sağlıyor.\n",
        "data.hist(figsize=(20, 15), bins=50)\n",
        "plt.suptitle('Değişkenlerin Dağılımı', fontsize=20) # Ana başlık ekliyorum\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # Başlığın grafiklerle çakışmaması için düzenleme\n",
        "plt.show()\n",
        "\n",
        "# Değişkenler arasındaki korelasyonu bir ısı haritası (heatmap) ile inceliyorum.\n",
        "# Bu, hangi değişkenlerin birbiriyle güçlü bir ilişki içinde olduğunu görmemi sağlıyor.\n",
        "corr_matrix = data.corr()\n",
        "plt.figure(figsize=(18, 15))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
        "plt.title('Değişkenler Arasındaki Korelasyon Matrisi')\n",
        "plt.show()\n",
        "\n",
        "# Aykırı değerleri (outliers) tespit etmek için her bir sütun için kutu grafikleri çiziyorum.\n",
        "# Kutu grafikleri, verinin çeyrekler arası dağılımını ve kutunun dışındaki aykırı noktaları gösterir.\n",
        "plt.figure(figsize=(15,60)) # Büyük bir figür boyutu, tüm grafikleri sığdırmak için\n",
        "for i,col in enumerate(df_new.columns,1):\n",
        "  plt.subplot(12, 2, i) # 12 satır, 2 sütunlu bir ızgarada her grafiği yerleştiriyorum\n",
        "  sns.boxplot(x=data[col])\n",
        "  plt.title(f'{col} İçin Kutu Grafiği')\n",
        "plt.tight_layout() # Grafikler arasında boşluk bırakarak çakışmayı önlüyorum\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "HqfQXB_TEoKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Aykırı değerleri IQR (Interquartile Range) yöntemi ile kırpıyorum (capping).\n",
        "# Bu işlem, aykırı değerleri silmek yerine, onları belirli bir üst veya alt sınıra sabitler.\n",
        "# Böylece veri kaybı yaşamadan modelin aykırı değerlerden olumsuz etkilenmesini önlüyorum.\n",
        "print(\"Aykırı Değerleri Kırpma İşlemi (IQR Yöntemiyle):\")\n",
        "for col in df_new:\n",
        "    Q1 = data[col].quantile(0.25)\n",
        "    Q3 = data[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "    data[col] = data[col].clip(lower_bound, upper_bound) # Değerleri belirlenen aralıkta tutuyorum\n",
        "    print(f\"'{col}' sütunundaki aykırı değerler [{lower_bound:.2f}, {upper_bound:.2f}] aralığına kırpıldı.\")\n",
        "print(\"---------------------\")\n",
        "\n",
        "# Aykırı değerleri kırptıktan sonra kutu grafiklerini tekrar çizerek değişimi gözlemliyorum.\n",
        "# Bu, kırpma işleminin ne kadar etkili olduğunu görsel olarak doğrulamamı sağlıyor.\n",
        "plt.figure(figsize=(15,60))\n",
        "for i,col in enumerate(df_new.columns,1):\n",
        "  plt.subplot(12, 2, i)\n",
        "  sns.boxplot(x=data[col])\n",
        "  plt.title(f'{col} İçin Kutu Grafiği (Kırpma Sonrası)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "lBuG4Y8eE3d9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Bu kısmı kodlarken Gemini'den yardımm aldım.\n",
        "# Yüksek korelasyonlu değişkenleri tespit etmek için sayısal verilerimi seçiyorum.\n",
        "numeric_data = data.select_dtypes(include=[np.number])\n",
        "corr_matrix = numeric_data.corr().abs() # Mutlak değer alarak hem pozitif hem negatif güçlü ilişkileri yakalıyorum.\n",
        "\n",
        "# Korelasyonu 0.80 ve üzeri olan sütunları görselleştirmek için bir maske oluşturuyorum.\n",
        "# Bu maske, ısı haritasında sadece güçlü ilişkileri göstererek görseli sadeleştiriyor.\n",
        "mask = np.triu(np.ones_like(corr_matrix, dtype=bool)) # Matrisin üst üçgenini gizliyorum\n",
        "mask = mask | (corr_matrix < 0.80) # 0.80'den küçük korelasyonları da gizliyorum\n",
        "\n",
        "plt.figure(figsize=(18, 15))\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", mask=mask)\n",
        "plt.title('Korelasyonu 0.80 ve Üzeri Olan Sütunlar')\n",
        "plt.show()\n",
        "\n",
        "# Veri setimdeki mevcut sütunları görüntülüyorum.\n",
        "print(\"Veri setimdeki son sütunlar:\")\n",
        "print(data.columns)\n"
      ],
      "metadata": {
        "id": "SqqWdsLgE8Gd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Yüksek korelasyonlu sütunları veri setimden çıkarıyorum.\n",
        "# Bu kararı, iş mantığıma ve değişkenlerin bilgi tekrarına dayanarak verdim.\n",
        "# 'MINIMUM_PAYMENTS', 'PURCHASES_TRX', 'CASH_ADVANCE_TRX' gibi sütunlar,\n",
        "# zaten diğer benzer sütunlarla (örn. BALANCE, PURCHASES, CASH_ADVANCE) yüksek korelasyona sahipti.\n",
        "df = data.drop(['MINIMUM_PAYMENTS', 'PURCHASES_TRX', 'CASH_ADVANCE_TRX'], axis=1)\n",
        "print(\"Yüksek korelasyonlu sütunlar silindikten sonra kalan sütunlar:\")\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "Gr1GXBXAFF4E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# K-Means algoritması için veriyi Standardizasyon (Ölçekleme) işlemi yapıyorum.\n",
        "# K-Means, mesafeye dayalı bir algoritma olduğu için, tüm değişkenlerin aynı ölçekte olması hayati önem taşır.\n",
        "# StandardScaler, veriyi ortalaması 0 ve standart sapması 1 olacak şekilde dönüştürüyor.\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "X = df.copy() # Kümeleme yapacağım veriyi kopyalıyorum\n",
        "scaler = StandardScaler() # Ölçekleyici objemi oluşturuyorum\n",
        "X_scaled = scaler.fit_transform(X) # Veriyi ölçekliyorum\n",
        "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns) # Ölçeklenmiş veriyi DataFrame'e dönüştürüyorum\n"
      ],
      "metadata": {
        "id": "STTMl-qdFCrJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Optimum küme sayısını (k) bulmak için Dirsek Yöntemini (Elbow Method) kullanıyorum.\n",
        "# WCSS (Küme İçi Kareler Toplamı), k arttıkça azalır; grafiğin \"dirsek\" yaptığı nokta ideal k'yi gösterir.\n",
        "from sklearn.cluster import KMeans\n",
        "wcss = [] # WCSS değerlerini saklamak için boş bir liste\n",
        "k_values = range(1, 11) # Deneyeceğim k değerleri aralığı\n",
        "\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
        "    kmeans.fit(X_scaled_df) # Ölçeklenmiş veriye modeli uyguluyorum\n",
        "    wcss.append(kmeans.inertia_) # Modelin inertia_ özelliği WCSS değerini verir\n",
        "\n",
        "# Dirsek grafiğini çizdiriyorum.\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_values, wcss, marker='o', linestyle='--')\n",
        "plt.title('Dirsek Yöntemi (Elbow Method)')\n",
        "plt.xlabel('Küme Sayısı (k)')\n",
        "plt.ylabel('Küme İçi Kareler Toplamı (WCSS)')\n",
        "plt.xticks(k_values) # x ekseni etiketlerini k değerleriyle eşleştiriyorum\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "4k3E0euCFJ9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dirsek Yöntemi net bir sonuç vermediği için Silüet Skorunu deniyorum.\n",
        "# Silüet Skoru, kümelerin ne kadar iyi ayrıldığını ve veri noktalarının kendi kümelerine ne kadar uyduğunu ölçer.\n",
        "from sklearn.metrics import silhouette_score\n",
        "silhouette_scores = [] # Silüet skorlarını saklamak için boş bir liste\n",
        "k_values = range(2, 11) # k=1 için Silüet Skoru hesaplanamaz, bu yüzden 2'den başlıyorum\n",
        "\n",
        "for k in k_values:\n",
        "    kmeans = KMeans(n_clusters=k, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
        "    cluster_labels = kmeans.fit_predict(X_scaled_df) # Kümeleri tahmin ediyorum\n",
        "    score = silhouette_score(X_scaled_df, cluster_labels) # Skoru hesaplıyorum\n",
        "    silhouette_scores.append(score)\n",
        "\n",
        "# Silüet skorlarının grafiğini çizdiriyorum.\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(k_values, silhouette_scores, marker='o', linestyle='--')\n",
        "plt.title('Silüet Skoru Yöntemi')\n",
        "plt.xlabel('Küme Sayısı (k)')\n",
        "plt.ylabel('Ortalama Silüet Skoru')\n",
        "plt.xticks(k_values)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# En yüksek Silüet skorunu veren k değerini buluyorum.\n",
        "optimal_k = k_values[silhouette_scores.index(max(silhouette_scores))]\n",
        "print(f\"En yüksek Silüet skorunu veren k değeri: {optimal_k}\")\n",
        "print(f\"En yüksek Silüet Skoru: {max(silhouette_scores):.2f}\")\n"
      ],
      "metadata": {
        "id": "wKnlNZBcFTAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ÖNEMLİ KARAR NOKTASI: K-Means Modeli Oluşturma\n",
        "# Dirsek grafiği belirgin bir dirsek noktası sunmasa da, k=4'ün mantıklı bir ayrım olabileceğini gözlemledim.\n",
        "# Silüet skoru grafiği ise en yüksek değeri k=2 için gösterdi.\n",
        "# Ancak k=2 gibi çok az sayıda küme, müşterileri \"iyi\" ve \"kötü\" gibi çok genel gruplara ayırarak\n",
        "# pazarlama stratejileri için yeterli çeşitliliği sunmuyordu.\n",
        "# Bu nedenle, Dirsek Yöntemi'nin işaret ettiği ve iş mantığıma daha uygun olan k=4'ü optimum küme sayısı olarak seçtim.\n",
        "# Daha yüksek bir küme sayısı olan k=7'yi tercih etmedim çünkü bu, segmentlerin çok fazla alt gruba ayrılmasına\n",
        "# ve bazı segmentlerin çok az sayıda müşteriden oluşmasına neden oluyordu.\n",
        "# Bu durum, her bir segment için anlamlı ve uygulanabilir bir pazarlama stratejisi belirlemeyi zorlaştıracaktı.\n",
        "from sklearn.cluster import KMeans\n",
        "kmeans_4 = KMeans(n_clusters=4, init='k-means++', max_iter=300, n_init=10, random_state=42)\n",
        "df['Segment_4'] = kmeans_4.fit_predict(X_scaled_df) # Müşterileri 4 segmente ayırıyorum\n",
        "\n",
        "# Her segmentteki müşteri sayısını görüntülüyorum.\n",
        "print(\"K=4 için Segment Dağılımı:\")\n",
        "print(df['Segment_4'].value_counts())\n",
        "\n",
        "# Segmentlerin ortalama değerlerini inceleyerek her bir segmentin profilini çıkarıyorum.\n",
        "segment_profiles_4 = df.groupby('Segment_4').mean()\n",
        "print(\"\\nK=4 için Segment Profilleri (Ortalama Değerler):\")\n",
        "print(segment_profiles_4)"
      ],
      "metadata": {
        "id": "scvDVW7rFYHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sayısal segment etiketlerini anlamlı isimlere dönüştürüyorum.\n",
        "df['Segment_Name_loc'] = ''\n",
        "df.loc[df['Segment_4'] == 0, 'Segment_Name_loc'] = 'Cash_Advance_Users'\n",
        "df.loc[df['Segment_4'] == 1, 'Segment_Name_loc'] = 'Passive_Users'\n",
        "df.loc[df['Segment_4'] == 2, 'Segment_Name_loc'] = 'Installment_Shoppers'\n",
        "df.loc[df['Segment_4'] == 3, 'Segment_Name_loc'] = 'Affluent_High_Spenders'\n",
        "\n",
        "print(\"\\nSegment İsimlerine göre müşteri sayısı (doğrulama):\")\n",
        "print(df['Segment_Name_loc'].value_counts())\n",
        "print(\"\\nYeni DataFrame'imin ilk 5 satırı (Segment_Name_loc sütunu ile):\")\n",
        "print(df[\"Segment_Name_loc\"].head())\n",
        "\n",
        "# Orijinal sayısal segment sütununu ('Segment_4') siliyorum.\n",
        "# Artık daha anlamlı olan 'Segment_Name_loc' sütunum var ve veri tekrarını önlüyorum.\n",
        "df.drop(\"Segment_4\", axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "N67YLfVaFej1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kümeleme öncesi ve sonrası veri dağılımını görselleştiriyorum.\n",
        "# Bu, K-Means algoritmasının veriyi nasıl anlamlı gruplara ayırdığını gözlemlememi sağlıyor.\n",
        "var1 = 'PURCHASES'\n",
        "var2 = 'CREDIT_LIMIT'\n",
        "\n",
        "# Kümeleme öncesi saçılım grafiği\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.scatterplot(x=df[var1], y=df[var2], alpha=0.6)\n",
        "plt.title('Kümeleme Öncesi Veri Dağılımı')\n",
        "plt.xlabel(var1)\n",
        "plt.ylabel(var2)\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "aMN1JUCqFgNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Kümeleme sonrası saçılım grafiği (segmentlere göre renklendirilmiş)\n",
        "plt.figure(figsize=(12, 8))\n",
        "sns.scatterplot(x=df[var1], y=df[var2], hue='Segment_Name_loc', palette='viridis', data=df)\n",
        "plt.title('Kümeleme Sonrası Veri Dağılımı (Segmentlere Göre)')\n",
        "plt.xlabel(var1)\n",
        "plt.ylabel(var2)\n",
        "plt.legend(title='Segmentler')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D01OOMJQForE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Burada Gemini'den yardım aldım.\n",
        "# Radar grafiği ile müşteri segmentlerinin profillerini detaylı inceliyorum.\n",
        "# Bu görselleştirme, her segmentin özelliklerini tek bir grafikte karşılaştırmamı sağlıyor ve\n",
        "# segmentler arasındaki farkları net bir şekilde ortaya koyuyor.\n",
        "# Seaborn'dan daha estetik bir stil ve renk paleti kullanıyorum.\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "segment_profiles_4 = df.groupby('Segment_Name_loc').mean()\n",
        "features = ['BALANCE', 'PURCHASES', 'CASH_ADVANCE', 'CREDIT_LIMIT', 'PAYMENTS', 'TENURE', 'PRC_FULL_PAYMENT']\n",
        "profile_df = segment_profiles_4[features]\n",
        "normalized_profile_df = (profile_df - profile_df.min()) / (profile_df.max() - profile_df.min())\n",
        "\n",
        "palette = sns.color_palette(\"Set2\", len(normalized_profile_df))\n",
        "fig, ax = plt.subplots(figsize=(12, 12), subplot_kw=dict(polar=True))\n",
        "\n",
        "angles = np.linspace(0, 2 * np.pi, len(features), endpoint=False).tolist()\n",
        "angles += angles[:1]\n",
        "features += features[:1]\n",
        "\n",
        "for i in range(len(normalized_profile_df)):\n",
        "    values = normalized_profile_df.iloc[i].values.tolist()\n",
        "    values += values[:1]\n",
        "    ax.plot(angles, values, linewidth=2.5, linestyle='solid', label=normalized_profile_df.index[i], color=palette[i])\n",
        "    ax.fill(angles, values, alpha=0.3, color=palette[i])\n",
        "\n",
        "ax.set_theta_offset(np.pi / 2)\n",
        "ax.set_theta_direction(-1)\n",
        "ax.set_rlabel_position(0)\n",
        "ax.set_yticklabels([])\n",
        "ax.set_xticks(angles[:-1])\n",
        "ax.set_xticklabels(features[:-1], fontsize=14, fontweight='bold')\n",
        "ax.set_title('Müşteri Segmentlerinin Detaylı Profili', size=20, y=1.1, fontweight='bold')\n",
        "ax.legend(loc='lower right', bbox_to_anchor=(0.1, -0.1), fontsize=12, ncol=1, frameon=False)\n",
        "\n",
        "for spine in ax.spines.values():\n",
        "    spine.set_edgecolor('lightgray')\n",
        "    spine.set_linewidth(0.5)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-Mo8f4L6Fvkn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}